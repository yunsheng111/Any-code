/**
 * 统一的 LLM API 调用服务
 *
 * 使用策略模式处理不同 LLM 提供商（OpenAI, Anthropic, Gemini）的 API 调用
 * 消除重复的 API 调用逻辑，提供统一的接口
 *
 * @module llmApiService
 */

import { fetch as tauriFetch } from '@tauri-apps/plugin-http';


/**
 * LLM API 格式类型
 */
export type ApiFormat = 'openai' | 'gemini' | 'anthropic';

/**
 * LLM 提供商配置接口
 */
export interface LLMProvider {
  id: string;
  name: string;
  apiUrl: string;
  apiKey: string;
  model: string;
  temperature?: number;
  maxTokens?: number;
  apiFormat?: ApiFormat;
  enabled?: boolean; // 用于配置管理
}

/**
 * API 请求参数
 */
export interface LLMRequest {
  systemPrompt: string;
  userPrompt: string;
  temperature?: number;
  maxTokens?: number;
}

/**
 * API 响应接口
 */
export interface LLMResponse {
  content: string;
  finishReason?: string;
}

/**
 * API 策略接口（策略模式核心）
 */
interface ApiStrategy {
  /**
   * 规范化 API URL
   */
  normalizeUrl(baseUrl: string): string;

  /**
   * 构建请求端点
   */
  buildEndpoint(normalizedUrl: string, model: string, apiKey: string): string;

  /**
   * 构建请求体
   */
  buildRequestBody(request: LLMRequest, model: string): any;

  /**
   * 构建请求头
   */
  buildHeaders(apiKey: string): Record<string, string>;

  /**
   * 解析响应
   */
  parseResponse(data: any): string;
}

/**
 * OpenAI API 策略实现
 */
class OpenAIStrategy implements ApiStrategy {
  normalizeUrl(baseUrl: string): string {
    let url = baseUrl.trim();

    // 移除末尾斜杠
    while (url.endsWith('/')) {
      url = url.slice(0, -1);
    }

    // 如果已经包含 /chat/completions，移除它
    if (url.endsWith('/chat/completions')) {
      url = url.slice(0, -'/chat/completions'.length);
    }

    // 如果不包含 /v1，添加它
    if (!url.endsWith('/v1')) {
      if (!url.match(/\/v\d+$/)) {
        url = `${url}/v1`;
      }
    }

    return url;
  }

  buildEndpoint(normalizedUrl: string): string {
    return `${normalizedUrl}/chat/completions`;
  }

  buildRequestBody(request: LLMRequest, model: string): any {
    const body: any = {
      model,
      messages: [
        { role: 'system', content: request.systemPrompt },
        { role: 'user', content: request.userPrompt }
      ],
      stream: false
    };

    if (request.temperature !== undefined && request.temperature !== null) {
      body.temperature = request.temperature;
    }
    if (request.maxTokens !== undefined && request.maxTokens !== null) {
      body.max_tokens = request.maxTokens;
    }

    return body;
  }

  buildHeaders(apiKey: string): Record<string, string> {
    return {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    };
  }

  parseResponse(data: any): string {
    if (!data.choices || data.choices.length === 0) {
      if (data.error) {
        throw new Error(`API error: ${JSON.stringify(data.error)}`);
      }
      throw new Error('API returned no choices');
    }

    const choice = data.choices[0];
    if (!choice.message) {
      throw new Error('Choice has no message');
    }

    const content = choice.message.content;
    if (!content || content.trim() === '') {
      if (choice.finish_reason) {
        throw new Error(`Content is empty. Finish reason: ${choice.finish_reason}`);
      }
      throw new Error('API returned empty content');
    }

    return content.trim();
  }
}

/**
 * Anthropic API 策略实现
 */
class AnthropicStrategy implements ApiStrategy {
  normalizeUrl(baseUrl: string): string {
    let url = baseUrl.trim();

    // 移除末尾斜杠
    while (url.endsWith('/')) {
      url = url.slice(0, -1);
    }

    // 如果已经包含 /messages，移除它
    if (url.endsWith('/messages')) {
      url = url.slice(0, -'/messages'.length);
    }

    // 如果不包含 /v1，添加它
    if (!url.endsWith('/v1')) {
      if (!url.match(/\/v\d+$/)) {
        url = `${url}/v1`;
      }
    }

    return url;
  }

  buildEndpoint(normalizedUrl: string): string {
    return `${normalizedUrl}/messages`;
  }

  buildRequestBody(request: LLMRequest, model: string): any {
    const body: any = {
      model,
      max_tokens: request.maxTokens || 4096,
      system: request.systemPrompt,
      messages: [
        { role: 'user', content: request.userPrompt }
      ],
    };

    if (request.temperature !== undefined && request.temperature !== null) {
      body.temperature = request.temperature;
    }

    return body;
  }

  buildHeaders(apiKey: string): Record<string, string> {
    return {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
    };
  }

  parseResponse(data: any): string {
    if (!data.content || data.content.length === 0) {
      if (data.error) {
        throw new Error(`Anthropic API error: ${JSON.stringify(data.error)}`);
      }
      throw new Error('Anthropic API returned no content');
    }

    const textContent = data.content.find((c: any) => c.type === 'text');
    if (!textContent || !textContent.text) {
      throw new Error('Anthropic API returned empty text content');
    }

    return textContent.text.trim();
  }
}

/**
 * Gemini API 策略实现
 */
class GeminiStrategy implements ApiStrategy {
  normalizeUrl(baseUrl: string): string {
    let url = baseUrl.trim();

    // 移除末尾斜杠
    while (url.endsWith('/')) {
      url = url.slice(0, -1);
    }

    return url;
  }

  buildEndpoint(normalizedUrl: string, model: string, apiKey: string): string {
    return `${normalizedUrl}/v1beta/models/${model}:generateContent?key=${apiKey}`;
  }

  buildRequestBody(request: LLMRequest): any {
    const body: any = {
      contents: [{
        parts: [
          { text: `${request.systemPrompt}\n\n${request.userPrompt}` }
        ]
      }],
    };

    const generationConfig: any = {};
    if (request.temperature !== undefined && request.temperature !== null) {
      generationConfig.temperature = request.temperature;
    }
    if (request.maxTokens !== undefined && request.maxTokens !== null) {
      generationConfig.maxOutputTokens = request.maxTokens;
    }

    if (Object.keys(generationConfig).length > 0) {
      body.generationConfig = generationConfig;
    }

    return body;
  }

  buildHeaders(): Record<string, string> {
    return {
      'Content-Type': 'application/json',
    };
  }

  parseResponse(data: any): string {
    const content = data.candidates?.[0]?.content?.parts?.[0]?.text;

    if (!content) {
      throw new Error('Gemini API returned empty response');
    }

    return content.trim();
  }
}

/**
 * 策略工厂函数
 */
function getApiStrategy(format: ApiFormat): ApiStrategy {
  switch (format) {
    case 'openai':
      return new OpenAIStrategy();
    case 'anthropic':
      return new AnthropicStrategy();
    case 'gemini':
      return new GeminiStrategy();
    default:
      return new OpenAIStrategy(); // 默认使用 OpenAI
  }
}

/**
 * 自动检测 API 格式
 */
export function detectApiFormat(apiUrl: string): ApiFormat {
  const url = apiUrl.toLowerCase().trim();

  // 检测 Gemini
  if (url.includes('generativelanguage.googleapis.com') ||
      url.includes('aiplatform.googleapis.com')) {
    return 'gemini';
  }

  // 检测 Anthropic
  if (url.includes('api.anthropic.com') ||
      url.includes('anthropic.com') ||
      url.includes('/v1/messages')) {
    return 'anthropic';
  }

  // 默认 OpenAI
  return 'openai';
}

/**
 * 统一的 LLM API 调用服务（主类）
 */
export class LLMApiService {
  /**
   * 统一的 API 调用方法
   *
   * @param provider LLM 提供商配置
   * @param request API 请求参数
   * @returns API 响应
   */
  static async call(
    provider: LLMProvider,
    request: LLMRequest
  ): Promise<LLMResponse> {
    // 1. 确定 API 格式
    const format = provider.apiFormat || detectApiFormat(provider.apiUrl);
    const strategy = getApiStrategy(format);
    // 2. URL 规范化
    const normalizedUrl = strategy.normalizeUrl(provider.apiUrl);

    // 3. 构建端点
    const endpoint = strategy.buildEndpoint(normalizedUrl, provider.model, provider.apiKey);

    // 4. 构建请求体
    const requestBody = strategy.buildRequestBody(
      {
        ...request,
        temperature: request.temperature ?? provider.temperature,
        maxTokens: request.maxTokens ?? provider.maxTokens,
      },
      provider.model
    );

    // 5. 构建请求头
    const headers = strategy.buildHeaders(provider.apiKey);

    // 6. 发送请求（统一的错误处理）
    try {
      const response = await tauriFetch(endpoint, {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(
          `${format} API request failed: ${response.status} ${response.statusText}\n${errorText}`
        );
      }

      // 7. 解析响应
      const data = await response.json();
      const content = strategy.parseResponse(data);

      return { content };

    } catch (error) {
      console.error(`[LLMApiService] ${format} API call failed:`, error);
      throw error;
    }
  }

  /**
   * 简化的调用接口（仅传递 system 和 user prompt）
   */
  static async callSimple(
    provider: LLMProvider,
    systemPrompt: string,
    userPrompt: string
  ): Promise<string> {
    const response = await this.call(provider, {
      systemPrompt,
      userPrompt,
    });
    return response.content;
  }
}

/**
 * 导出便利函数（向后兼容）
 */
export const normalizeOpenAIUrl = (url: string) => new OpenAIStrategy().normalizeUrl(url);
export const normalizeAnthropicUrl = (url: string) => new AnthropicStrategy().normalizeUrl(url);
export const normalizeGeminiUrl = (url: string) => new GeminiStrategy().normalizeUrl(url);

/**
 * 根据 API 格式规范化 URL（向后兼容）
 */
export function normalizeApiUrl(apiUrl: string, apiFormat?: ApiFormat): string {
  const format = apiFormat || detectApiFormat(apiUrl);
  const strategy = getApiStrategy(format);
  return strategy.normalizeUrl(apiUrl);
}
