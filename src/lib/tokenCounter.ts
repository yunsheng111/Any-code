/**
 * Official Claude Token Counter Service
 *
 * åŸºäºClaudeå®˜æ–¹Token Count APIçš„å‡†ç¡®tokenè®¡ç®—æœåŠ¡
 * æ”¯æŒæ‰€æœ‰æ¶ˆæ¯ç±»å‹å’ŒClaudeæ¨¡å‹çš„ç²¾ç¡®tokenç»Ÿè®¡å’Œæˆæœ¬è®¡ç®—
 *
 * 2025å¹´æœ€æ–°å®˜æ–¹å®šä»·å’ŒClaude 4ç³»åˆ—æ¨¡å‹æ”¯æŒ
 */

import Anthropic from '@anthropic-ai/sdk';
import { api } from './api';

// ============================================================================
// Claude Model Pricing - MUST MATCH BACKEND (usage.rs)
// âš ï¸ WARNING: This pricing table MUST be kept in sync with:
//    src-tauri/src/commands/usage.rs::ModelPricing
// Source: https://docs.claude.com/en/docs/about-claude/models/overview
// Last Updated: January 2025
// ============================================================================

export const CLAUDE_PRICING = {
  // Claude 4.5 Series (Latest - December 2025)
  'claude-opus-4-5': {
    input: 5.0,
    output: 25.0,
    cache_write: 6.25,
    cache_read: 0.50,
  },
  'claude-opus-4-5-20251101': {
    input: 5.0,
    output: 25.0,
    cache_write: 6.25,
    cache_read: 0.50,
  },
  'claude-sonnet-4-5': {
    input: 3.0,
    output: 15.0,
    cache_write: 3.75,
    cache_read: 0.30,
  },
  'claude-sonnet-4-5-20250929': {
    input: 3.0,
    output: 15.0,
    cache_write: 3.75,
    cache_read: 0.30,
  },
  'claude-haiku-4-5': {
    input: 1.0,
    output: 5.0,
    cache_write: 1.25,
    cache_read: 0.10,
  },
  'claude-haiku-4-5-20251001': {
    input: 1.0,
    output: 5.0,
    cache_write: 1.25,
    cache_read: 0.10,
  },
  // Claude 4.1 Series
  'claude-opus-4-1': {
    input: 15.0,
    output: 75.0,
    cache_write: 18.75,
    cache_read: 1.50,
  },
  'claude-opus-4-1-20250805': {
    input: 15.0,
    output: 75.0,
    cache_write: 18.75,
    cache_read: 1.50,
  },
  // é»˜è®¤å€¼ (ä½¿ç”¨æœ€æ–° Sonnet 4.5 å®šä»·)
  'default': {
    input: 3.0,
    output: 15.0,
    cache_write: 3.75,
    cache_read: 0.30,
  }
} as const;

// ============================================================================
// AI Model Context Windows
// å„æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆtokensï¼‰
// Claude: https://docs.claude.com/en/docs/about-claude/models/overview
// Codex: https://github.com/openai/codex (å®˜æ–¹æ–‡æ¡£)
// ============================================================================

export const CLAUDE_CONTEXT_WINDOWS = {
  // Claude 4.5 Series
  'claude-opus-4-5': 200000,
  'claude-opus-4-5-20251101': 200000,
  'claude-sonnet-4-5': 200000,
  'claude-sonnet-4-5-20250929': 200000,
  'claude-haiku-4-5': 200000,
  'claude-haiku-4-5-20251001': 200000,
  // Claude 4.1 Series
  'claude-opus-4-1': 200000,
  'claude-opus-4-1-20250805': 200000,
  // é»˜è®¤å€¼
  'default': 200000,
} as const;

// ============================================================================
// Codex Model Context Windows
// Source: Codex CLI history token_count events expose model_context_window (e.g. 272000 for gpt-5-codex)
// ============================================================================

export const CODEX_CONTEXT_WINDOWS = {
  // GPT-5.1-Codex ç³»åˆ— - Codex CLI ä¸»è¦ä½¿ç”¨çš„æ¨¡å‹
  // 272K context window
  'gpt-5.1-codex': 272000,
  'gpt-5.1-codex-mini': 272000,
  'gpt-5.1-codex-max': 272000,
  'gpt-5-codex': 272000,
  // codex-mini-latest - é»˜è®¤ Codex CLI æ¨¡å‹
  // 272K context window
  'codex-mini-latest': 272000,
  // GPT-5.2 ç³»åˆ— - æœ€æ–°æ¨¡å‹
  // 272K context, 128K max output
  'gpt-5.2': 272000,
  'gpt-5.2-codex': 272000,  // ğŸ†• GPT-5.2-Codexï¼ˆ2025å¹´12æœˆ18æ—¥å‘å¸ƒï¼‰
  'gpt-5.2-instant': 272000,
  'gpt-5.2-thinking': 272000,
  'gpt-5.2-pro': 272000,
  // o4-mini (Codex åº•å±‚æ¨¡å‹)
  'o4-mini': 128000,
  // é»˜è®¤å€¼ - ä½¿ç”¨ codex-mini-latest çš„çª—å£å¤§å°
  'default': 272000,
} as const;

// ============================================================================
// Gemini Model Context Windows
// Source: https://ai.google.dev/gemini-api/docs/models (and model cards)
// NOTE: Current app configuration uses 1M context across supported Gemini models.
// ============================================================================

export const GEMINI_CONTEXT_WINDOWS = {
  'gemini-3-pro-preview': 1_000_000,
  'gemini-3-pro-image-preview': 1_000_000,
  'gemini-2.5-pro': 1_000_000,
  'gemini-2.5-flash': 1_000_000,
  'gemini-2.5-flash-lite': 1_000_000,
  'gemini-2.0-flash': 1_000_000,
  'gemini-2.0-flash-exp': 1_000_000,
  'default': 1_000_000,
} as const;

/**
 * è·å–æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°
 * @param model - æ¨¡å‹åç§°
 * @param engine - å¼•æ“ç±»å‹ï¼ˆclaude/codex/geminiï¼‰
 * @returns ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆtokensï¼‰
 */
export function getContextWindowSize(model?: string, engine?: string): number {
  // Gemini å¼•æ“
  if (engine === 'gemini') {
    if (!model) return GEMINI_CONTEXT_WINDOWS['default'];

    const lowerModel = model.toLowerCase();

    // å¤„ç† Vertex AI / provider å‰ç¼€ä¸ç‰ˆæœ¬åç¼€
    const normalized = lowerModel
      .replace('google.', '')
      .replace('vertex.', '')
      .replace('-v1:0', '')
      .split('@')[0];

    if (normalized in GEMINI_CONTEXT_WINDOWS) {
      return GEMINI_CONTEXT_WINDOWS[normalized as keyof typeof GEMINI_CONTEXT_WINDOWS];
    }

    // å¸¸è§å˜ä½“ï¼š-exp / -preview / ç‰ˆæœ¬æ—¥æœŸåç¼€ç­‰ -> å›é€€åˆ°å®¶æ—é»˜è®¤ 1M
    if (normalized.startsWith('gemini-')) {
      return GEMINI_CONTEXT_WINDOWS['default'];
    }

    return GEMINI_CONTEXT_WINDOWS['default'];
  }

  // Codex å¼•æ“
  if (engine === 'codex') {
    if (!model) return CODEX_CONTEXT_WINDOWS['default'];

    const lowerModel = model.toLowerCase();

    // å°è¯•ç›´æ¥åŒ¹é…
    if (lowerModel in CODEX_CONTEXT_WINDOWS) {
      return CODEX_CONTEXT_WINDOWS[lowerModel as keyof typeof CODEX_CONTEXT_WINDOWS];
    }

    // GPT-5.1-Codex ç³»åˆ—
    if (lowerModel.includes('5.1-codex-max') || lowerModel.includes('5_1_codex_max')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.1-codex-max'];
    }
    if (lowerModel.includes('5.1-codex-mini') || lowerModel.includes('5_1_codex_mini')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.1-codex-mini'];
    }
    if (lowerModel.includes('5.1-codex') || lowerModel.includes('5_1_codex')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.1-codex'];
    }

    // GPT-5.2 ç³»åˆ— (Codex, Instant, Thinking, Pro variants)
    // GPT-5.2-Codex ä¼˜å…ˆåŒ¹é…ï¼ˆæœ€æ–°ä»£ç æ¨¡å‹ï¼‰
    if (lowerModel.includes('5.2-codex') || lowerModel.includes('5_2_codex')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.2-codex'];
    }
    if (lowerModel.includes('5.2-pro') || lowerModel.includes('5_2_pro')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.2-pro'];
    }
    if (lowerModel.includes('5.2-thinking') || lowerModel.includes('5_2_thinking')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.2-thinking'];
    }
    if (lowerModel.includes('5.2-instant') || lowerModel.includes('5_2_instant')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.2-instant'];
    }
    if (lowerModel.includes('gpt-5.2') || lowerModel.includes('gpt_5_2') || lowerModel.includes('5.2')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5.2'];
    }

    // o4-mini
    if (lowerModel.includes('o4-mini') || lowerModel.includes('o4_mini')) {
      return CODEX_CONTEXT_WINDOWS['o4-mini'];
    }

    // codex-mini-latest - é»˜è®¤ CLI æ¨¡å‹
    if (lowerModel.includes('codex-mini-latest') || lowerModel.includes('codex_mini_latest')) {
      return CODEX_CONTEXT_WINDOWS['codex-mini-latest'];
    }

    // gpt-5-codex (åˆ«å)
    if (lowerModel.includes('gpt-5-codex') || lowerModel.includes('gpt_5_codex')) {
      return CODEX_CONTEXT_WINDOWS['gpt-5-codex'];
    }

    // é€šç”¨ Codex åŒ¹é… - é»˜è®¤ä½¿ç”¨ codex-mini-latest (200K)
    if (lowerModel.includes('codex')) {
      return CODEX_CONTEXT_WINDOWS['codex-mini-latest'];
    }

    return CODEX_CONTEXT_WINDOWS['default'];
  }

  // Claude å¼•æ“ï¼ˆé»˜è®¤ï¼‰
  if (!model) return CLAUDE_CONTEXT_WINDOWS['default'];

  // å°è¯•ç›´æ¥åŒ¹é…
  if (model in CLAUDE_CONTEXT_WINDOWS) {
    return CLAUDE_CONTEXT_WINDOWS[model as keyof typeof CLAUDE_CONTEXT_WINDOWS];
  }

  // å°è¯•é€šè¿‡åˆ«ååŒ¹é…
  const normalizedModel = MODEL_ALIASES[model as keyof typeof MODEL_ALIASES];
  if (normalizedModel && normalizedModel in CLAUDE_CONTEXT_WINDOWS) {
    return CLAUDE_CONTEXT_WINDOWS[normalizedModel as keyof typeof CLAUDE_CONTEXT_WINDOWS];
  }

  return CLAUDE_CONTEXT_WINDOWS['default'];
}

// æ ‡å‡†åŒ–æ¨¡å‹åç§°æ˜ å°„
export const MODEL_ALIASES = {
  'opus': 'claude-opus-4-5', // é»˜è®¤æœ€æ–°ç‰ˆæœ¬
  'opus4.5': 'claude-opus-4-5',
  'opus-4.5': 'claude-opus-4-5',
  'opus4.1': 'claude-opus-4-1',
  'opus-4.1': 'claude-opus-4-1',
  'sonnet': 'claude-sonnet-4-5', // é»˜è®¤æœ€æ–°ç‰ˆæœ¬
  'sonnet4.5': 'claude-sonnet-4-5',
  'sonnet-4.5': 'claude-sonnet-4-5',
  'haiku': 'claude-haiku-4-5', // é»˜è®¤æœ€æ–°ç‰ˆæœ¬
  'haiku4.5': 'claude-haiku-4-5',
  'haiku-4.5': 'claude-haiku-4-5',
} as const;

/**
 * âœ… Tokenä½¿ç”¨ç»Ÿè®¡æ¥å£
 *
 * @deprecated Consider using StandardizedTokenUsage from tokenExtractor.ts for new code.
 * This interface is kept for backward compatibility with existing code.
 *
 * For new implementations:
 * - Use `StandardizedTokenUsage` from tokenExtractor.ts (fully normalized with total_tokens)
 * - Use `RawTokenUsage` from tokenExtractor.ts (for handling various API response formats)
 * - Use `normalizeRawUsage()` from tokenExtractor.ts to convert raw data to standard format
 */
export interface TokenUsage {
  input_tokens?: number;
  output_tokens?: number;
  cache_creation_input_tokens?: number;
  cache_creation_tokens?: number;
  cache_read_input_tokens?: number;
  cache_read_tokens?: number;
}

// æ¶ˆæ¯æ¥å£
export interface ClaudeMessage {
  role: 'user' | 'assistant' | 'system';
  content: string | Array<{
    type: 'text' | 'image' | 'document';
    text?: string;
    source?: {
      type: 'base64';
      media_type: string;
      data: string;
    };
  }>;
}

// å·¥å…·å®šä¹‰æ¥å£
export interface ClaudeTool {
  name: string;
  description: string;
  input_schema: {
    type: 'object';
    properties: Record<string, any>;
    required?: string[];
  };
}

// Tokenè®¡ç®—å“åº”æ¥å£
export interface TokenCountResponse {
  input_tokens: number;
  cache_creation_input_tokens?: number;
  cache_read_input_tokens?: number;
}

// æˆæœ¬åˆ†æç»“æœ
export interface CostBreakdown {
  input_cost: number;
  output_cost: number;
  cache_write_cost: number;
  cache_read_cost: number;
  total_cost: number;
  total: number; // å‘åå…¼å®¹å­—æ®µ
}

// Tokenæ˜ç»†åˆ†æ
export interface TokenBreakdown {
  total: number;
  input: number;
  output: number;
  cache_write: number;
  cache_read: number;
  cost: CostBreakdown;
  efficiency: {
    cache_hit_rate: number;
    cost_savings: number;
  };
}

export class TokenCounterService {
  private client: Anthropic | null = null;
  private apiKey: string | null = null;
  private baseURL: string | null = null;

  constructor() {
    this.initialize();
  }

  /**
   * åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯
   */
  private async initialize() {
    try {
      // ä»å¤šä¸ªæ¥æºè·å–APIå¯†é’¥
      this.apiKey = this.getApiKey();
      this.baseURL = this.getBaseURL();

      if (this.apiKey) {
        this.client = new Anthropic({
          apiKey: this.apiKey,
          baseURL: this.baseURL || undefined,
          defaultHeaders: {
            'anthropic-beta': 'prompt-caching-2024-07-31,token-counting-2024-11-01',
          },
        });
      }
    } catch (error) {
      console.warn('[TokenCounter] åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ä¼°ç®—æ–¹æ³•:', error);
    }
  }

  /**
   * è·å–APIå¯†é’¥
   */
  private getApiKey(): string | null {
    // 1. ç¯å¢ƒå˜é‡
    if (typeof window !== 'undefined') {
      // æµè§ˆå™¨ç¯å¢ƒ
      return null; // æµè§ˆå™¨ä¸­ä¸åº”ç›´æ¥ä½¿ç”¨APIå¯†é’¥
    }

    // Node.jsç¯å¢ƒ
    return process.env.ANTHROPIC_API_KEY ||
           process.env.ANTHROPIC_AUTH_TOKEN ||
           null;
  }

  /**
   * è·å–åŸºç¡€URL
   */
  private getBaseURL(): string | null {
    if (typeof window !== 'undefined') {
      return localStorage.getItem('anthropic_base_url');
    }

    return process.env.ANTHROPIC_BASE_URL ||
           process.env.CLAUDE_API_BASE_URL ||
           null;
  }

  /**
   * æ ‡å‡†åŒ–æ¨¡å‹åç§°
   * âš ï¸ MUST MATCH: src-tauri/src/commands/usage.rs::parse_model_family
   *
   * This function replicates the backend logic to ensure consistent
   * model identification and pricing across frontend and backend.
   */
  public normalizeModel(model?: string): string {
    if (!model) return 'claude-sonnet-4-5-20250929';

    // Normalize: lowercase + remove common prefixes/suffixes
    let normalized = model.toLowerCase();
    normalized = normalized.replace('anthropic.', '');
    normalized = normalized.replace('-v1:0', '');

    // Handle @ symbol for Vertex AI format
    const atIndex = normalized.indexOf('@');
    if (atIndex !== -1) {
      normalized = normalized.substring(0, atIndex);
    }

    // Priority-based matching (order matters! MUST match backend logic)

    // Claude 4.5 Series (Latest)
    if (normalized.includes('opus') && (normalized.includes('4.5') || normalized.includes('4-5'))) {
      return 'claude-opus-4-5';
    }
    if (normalized.includes('haiku') && (normalized.includes('4.5') || normalized.includes('4-5'))) {
      return 'claude-haiku-4-5';
    }
    if (normalized.includes('sonnet') && (normalized.includes('4.5') || normalized.includes('4-5'))) {
      return 'claude-sonnet-4-5';
    }

    // Claude 4.1 Series
    if (normalized.includes('opus') && (normalized.includes('4.1') || normalized.includes('4-1'))) {
      return 'claude-opus-4-1';
    }

    // Generic family detection (fallback - MUST match backend)
    if (normalized.includes('haiku')) {
      return 'claude-haiku-4-5'; // Default to latest
    }
    if (normalized.includes('opus')) {
      return 'claude-opus-4-5'; // Default to latest
    }
    if (normalized.includes('sonnet')) {
      return 'claude-sonnet-4-5'; // Default to latest
    }

    // Unknown model - return original
    console.warn(`[TokenCounter] Unknown model: '${model}'. Using default pricing.`);
    return model;
  }

  /**
   * ä½¿ç”¨å®˜æ–¹APIè®¡ç®—tokenæ•°é‡
   */
  async countTokens(
    messages: ClaudeMessage[],
    model?: string,
    tools?: ClaudeTool[],
    systemPrompt?: string
  ): Promise<TokenCountResponse> {
    const normalizedModel = this.normalizeModel(model);

    // å¦‚æœå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼°ç®—æ–¹æ³•
    if (!this.client) {
      return this.estimateTokens(messages, tools, systemPrompt);
    }

    try {
      const requestData: any = {
        model: normalizedModel,
        messages: messages.map(msg => ({
          role: msg.role,
          content: msg.content,
        })),
      };

      if (tools && tools.length > 0) {
        requestData.tools = tools;
      }

      if (systemPrompt) {
        requestData.system = systemPrompt;
      }

      const response = await this.client.messages.countTokens(requestData);

      return {
        input_tokens: response.input_tokens,
        cache_creation_input_tokens: (response as any).cache_creation_input_tokens,
        cache_read_input_tokens: (response as any).cache_read_input_tokens,
      };
    } catch (error) {
      console.warn('[TokenCounter] APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—æ–¹æ³•:', error);
      return this.estimateTokens(messages, tools, systemPrompt);
    }
  }

  /**
   * é™çº§ä¼°ç®—æ–¹æ³•ï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰
   */
  private estimateTokens(
    messages: ClaudeMessage[],
    tools?: ClaudeTool[],
    systemPrompt?: string
  ): TokenCountResponse {
    let totalTokens = 0;

    // ä¼°ç®—æ¶ˆæ¯token
    for (const message of messages) {
      if (typeof message.content === 'string') {
        totalTokens += Math.ceil(message.content.length / 4); // ç²—ç•¥ä¼°ç®—ï¼š4å­—ç¬¦=1token
      } else if (Array.isArray(message.content)) {
        for (const content of message.content) {
          if (content.type === 'text' && content.text) {
            totalTokens += Math.ceil(content.text.length / 4);
          } else if (content.type === 'image') {
            totalTokens += 1551; // åŸºäºå®˜æ–¹æ–‡æ¡£çš„å›¾åƒtokenä¼°ç®—
          } else if (content.type === 'document') {
            totalTokens += 2188; // åŸºäºå®˜æ–¹æ–‡æ¡£çš„PDF tokenä¼°ç®—
          }
        }
      }
    }

    // ä¼°ç®—ç³»ç»Ÿæç¤ºtoken
    if (systemPrompt) {
      totalTokens += Math.ceil(systemPrompt.length / 4);
    }

    // ä¼°ç®—å·¥å…·å®šä¹‰token
    if (tools && tools.length > 0) {
      const toolsJson = JSON.stringify(tools);
      totalTokens += Math.ceil(toolsJson.length / 4);
    }

    return {
      input_tokens: totalTokens,
    };
  }

  /**
   * æ‰¹é‡è®¡ç®—tokenï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
   */
  async batchCountTokens(
    requests: Array<{
      messages: ClaudeMessage[];
      model?: string;
      tools?: ClaudeTool[];
      systemPrompt?: string;
    }>
  ): Promise<TokenCountResponse[]> {
    try {
      const promises = requests.map(req =>
        this.countTokens(req.messages, req.model, req.tools, req.systemPrompt)
      );
      return await Promise.all(promises);
    } catch (error) {
      console.error('[TokenCounter] æ‰¹é‡è®¡ç®—å¤±è´¥:', error);
      // é™çº§åˆ°é€ä¸ªè®¡ç®—
      const results: TokenCountResponse[] = [];
      for (const req of requests) {
        try {
          const result = await this.countTokens(req.messages, req.model, req.tools, req.systemPrompt);
          results.push(result);
        } catch (err) {
          results.push({ input_tokens: 0 });
        }
      }
      return results;
    }
  }

  /**
   * è®¡ç®—æˆæœ¬
   */
  calculateCost(usage: TokenUsage, model?: string): CostBreakdown {
    const normalizedModel = this.normalizeModel(model);
    const pricing = CLAUDE_PRICING[normalizedModel as keyof typeof CLAUDE_PRICING];

    if (!pricing) {
      console.warn(`[TokenCounter] æœªçŸ¥æ¨¡å‹å®šä»·: ${normalizedModel}`);
      return {
        input_cost: 0,
        output_cost: 0,
        cache_write_cost: 0,
        cache_read_cost: 0,
        total_cost: 0,
        total: 0, // å‘åå…¼å®¹å­—æ®µ
      };
    }

    const input_tokens = usage.input_tokens || 0;
    const output_tokens = usage.output_tokens || 0;
    const cache_write_tokens = usage.cache_creation_input_tokens || usage.cache_creation_tokens || 0;
    const cache_read_tokens = usage.cache_read_input_tokens || usage.cache_read_tokens || 0;

    const input_cost = (input_tokens * pricing.input) / 1_000_000;
    const output_cost = (output_tokens * pricing.output) / 1_000_000;
    const cache_write_cost = (cache_write_tokens * pricing.cache_write) / 1_000_000;
    const cache_read_cost = (cache_read_tokens * pricing.cache_read) / 1_000_000;

    const total_cost = input_cost + output_cost + cache_write_cost + cache_read_cost;
    return {
      input_cost,
      output_cost,
      cache_write_cost,
      cache_read_cost,
      total_cost,
      total: total_cost, // å‘åå…¼å®¹å­—æ®µ
    };
  }

  /**
   * è·å–è¯¦ç»†çš„tokenæ˜ç»†åˆ†æ
   */
  calculateBreakdown(usage: TokenUsage, model?: string): TokenBreakdown {
    const normalized = this.normalizeUsage(usage);
    const cost = this.calculateCost(normalized, model);

    const total = normalized.input_tokens + normalized.output_tokens +
                 (normalized.cache_creation_tokens || 0) + (normalized.cache_read_tokens || 0);

    const cache_hit_rate = total > 0 ? ((normalized.cache_read_tokens || 0) / total) * 100 : 0;

    // è®¡ç®—ç¼“å­˜èŠ‚çº¦çš„æˆæœ¬
    const standard_cost = ((normalized.cache_read_tokens || 0) *
                          (CLAUDE_PRICING[this.normalizeModel(model) as keyof typeof CLAUDE_PRICING]?.input || 3)) / 1_000_000;
    const actual_cache_cost = cost.cache_read_cost;
    const cost_savings = standard_cost - actual_cache_cost;

    return {
      total,
      input: normalized.input_tokens,
      output: normalized.output_tokens,
      cache_write: normalized.cache_creation_tokens || 0,
      cache_read: normalized.cache_read_tokens || 0,
      cost,
      efficiency: {
        cache_hit_rate,
        cost_savings,
      },
    };
  }

  /**
   * æ ‡å‡†åŒ–tokenä½¿ç”¨æ•°æ®
   *
   * âš ï¸ This method now delegates to tokenExtractor.ts for unified token normalization.
   * All token standardization logic is centralized in tokenExtractor.ts
   */
  normalizeUsage(usage: TokenUsage): Required<TokenUsage> {
    // Import from tokenExtractor for unified normalization
    const { normalizeRawUsage } = require('./tokenExtractor');
    const standardized = normalizeRawUsage(usage);

    // Return in the expected TokenUsage format
    return {
      input_tokens: standardized.input_tokens,
      output_tokens: standardized.output_tokens,
      cache_creation_input_tokens: standardized.cache_creation_tokens,
      cache_creation_tokens: standardized.cache_creation_tokens,
      cache_read_input_tokens: standardized.cache_read_tokens,
      cache_read_tokens: standardized.cache_read_tokens,
    };
  }

  /**
   * æ ¼å¼åŒ–tokenæ•°é‡æ˜¾ç¤º
   */
  formatCount(count: number): string {
    if (count >= 1_000_000) {
      return `${(count / 1_000_000).toFixed(2)}M`;
    } else if (count >= 1_000) {
      return `${(count / 1_000).toFixed(1)}K`;
    }
    return count.toLocaleString();
  }

  /**
   * æ ¼å¼åŒ–æˆæœ¬æ˜¾ç¤º
   */
  formatCost(cost: number): string {
    if (cost >= 1) {
      return `$${cost.toFixed(2)}`;
    } else if (cost >= 0.01) {
      return `$${cost.toFixed(3)}`;
    } else if (cost >= 0.001) {
      return `$${cost.toFixed(4)}`;
    } else if (cost > 0) {
      return `$${cost.toFixed(6)}`;
    }
    return '$0.00';
  }

  /**
   * æ ¼å¼åŒ–tokenæ˜ç»†æ˜¾ç¤º
   */
  formatBreakdown(
    usage: TokenUsage,
    model?: string,
    options: {
      compact?: boolean;
      includeCost?: boolean;
      includeEfficiency?: boolean
    } = {}
  ): string {
    const breakdown = this.calculateBreakdown(usage, model);

    if (options.compact) {
      const parts: string[] = [];

      if (breakdown.input > 0) parts.push(`${this.formatCount(breakdown.input)} in`);
      if (breakdown.output > 0) parts.push(`${this.formatCount(breakdown.output)} out`);
      if (breakdown.cache_read > 0) parts.push(`${this.formatCount(breakdown.cache_read)} read`);

      let result = parts.join(', ');

      if (options.includeCost && breakdown.cost.total_cost > 0) {
        result += ` â€¢ ${this.formatCost(breakdown.cost.total_cost)}`;
      }

      if (options.includeEfficiency && breakdown.efficiency.cache_hit_rate > 0) {
        result += ` (${breakdown.efficiency.cache_hit_rate.toFixed(1)}% cached)`;
      }

      return result || `${this.formatCount(breakdown.total)} tokens`;
    }

    return `${this.formatCount(breakdown.total)} tokens`;
  }

  /**
   * åˆ›å»ºè¯¦ç»†çš„å·¥å…·æç¤ºå†…å®¹
   */
  createTooltip(usage: TokenUsage, model?: string): string {
    const breakdown = this.calculateBreakdown(usage, model);
    const normalizedModel = this.normalizeModel(model);
    const pricing = CLAUDE_PRICING[normalizedModel as keyof typeof CLAUDE_PRICING];

    const lines: string[] = [];

    lines.push(`æ¨¡å‹: ${normalizedModel}`);
    lines.push(`æ€»Token: ${breakdown.total.toLocaleString()}`);
    lines.push('');

    // Tokenæ˜ç»†
    if (breakdown.input > 0) {
      lines.push(`è¾“å…¥Token: ${breakdown.input.toLocaleString()}`);
    }
    if (breakdown.output > 0) {
      lines.push(`è¾“å‡ºToken: ${breakdown.output.toLocaleString()}`);
    }
    if (breakdown.cache_write > 0) {
      lines.push(`ç¼“å­˜å†™å…¥: ${breakdown.cache_write.toLocaleString()}`);
    }
    if (breakdown.cache_read > 0) {
      lines.push(`ç¼“å­˜è¯»å–: ${breakdown.cache_read.toLocaleString()}`);
    }

    // æˆæœ¬æ˜ç»†
    if (breakdown.cost.total_cost > 0) {
      lines.push('');
      lines.push(`æ€»æˆæœ¬: ${this.formatCost(breakdown.cost.total_cost)}`);

      if (breakdown.cost.input_cost > 0) {
        lines.push(`è¾“å…¥æˆæœ¬: ${this.formatCost(breakdown.cost.input_cost)}`);
      }
      if (breakdown.cost.output_cost > 0) {
        lines.push(`è¾“å‡ºæˆæœ¬: ${this.formatCost(breakdown.cost.output_cost)}`);
      }
      if (breakdown.cost.cache_write_cost > 0) {
        lines.push(`ç¼“å­˜å†™å…¥æˆæœ¬: ${this.formatCost(breakdown.cost.cache_write_cost)}`);
      }
      if (breakdown.cost.cache_read_cost > 0) {
        lines.push(`ç¼“å­˜è¯»å–æˆæœ¬: ${this.formatCost(breakdown.cost.cache_read_cost)}`);
      }
    }

    // æ•ˆç‡æŒ‡æ ‡
    if (breakdown.efficiency.cache_hit_rate > 0) {
      lines.push('');
      lines.push(`ç¼“å­˜å‘½ä¸­ç‡: ${breakdown.efficiency.cache_hit_rate.toFixed(1)}%`);
      if (breakdown.efficiency.cost_savings > 0) {
        lines.push(`æˆæœ¬èŠ‚çº¦: ${this.formatCost(breakdown.efficiency.cost_savings)}`);
      }
    }

    // å®šä»·ä¿¡æ¯
    if (pricing) {
      lines.push('');
      lines.push('å®šä»· (æ¯ç™¾ä¸‡token):');
      lines.push(`è¾“å…¥: $${pricing.input}`);
      lines.push(`è¾“å‡º: $${pricing.output}`);
      lines.push(`ç¼“å­˜å†™å…¥: $${pricing.cache_write}`);
      lines.push(`ç¼“å­˜è¯»å–: $${pricing.cache_read}`);
    }

    return lines.join('\n');
  }

  /**
   * è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
   */
  getSupportedModels(): string[] {
    return Object.keys(CLAUDE_PRICING);
  }

  /**
   * èšåˆå¤šä¸ªtokenä½¿ç”¨æ•°æ®
   */
  aggregateUsage(usages: TokenUsage[]): TokenUsage {
    return usages.reduce(
      (total, usage) => {
        const normalized = this.normalizeUsage(usage);
        return {
          input_tokens: (total.input_tokens || 0) + (normalized.input_tokens || 0),
          output_tokens: (total.output_tokens || 0) + (normalized.output_tokens || 0),
          cache_creation_tokens: (total.cache_creation_tokens || 0) + (normalized.cache_creation_tokens || 0),
          cache_read_tokens: (total.cache_read_tokens || 0) + (normalized.cache_read_tokens || 0),
          cache_creation_input_tokens: (total.cache_creation_input_tokens || 0) + (normalized.cache_creation_input_tokens || 0),
          cache_read_input_tokens: (total.cache_read_input_tokens || 0) + (normalized.cache_read_input_tokens || 0),
        };
      },
      { input_tokens: 0, output_tokens: 0, cache_creation_tokens: 0, cache_read_tokens: 0, cache_creation_input_tokens: 0, cache_read_input_tokens: 0 }
    );
  }

  /**
   * æ£€æŸ¥APIæ˜¯å¦å¯ç”¨
   */
  isApiAvailable(): boolean {
    return this.client !== null;
  }
}

/**
 * Session-level token statistics
 */
export interface SessionTokenStats {
  total_tokens: number;
  total_cost: number;
  message_count: number;
  average_tokens_per_message: number;
  cache_efficiency: number;
  breakdown: TokenBreakdown;
  trend: {
    tokens_per_hour: number;
    cost_per_hour: number;
    peak_usage_time?: string;
  };
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const tokenCounter = new TokenCounterService();

// ä¾¿åˆ©å‡½æ•°å¯¼å‡º
export const countTokens = (messages: ClaudeMessage[], model?: string, tools?: ClaudeTool[], systemPrompt?: string) =>
  tokenCounter.countTokens(messages, model, tools, systemPrompt);

export const calculateCost = (usage: TokenUsage, model?: string) =>
  tokenCounter.calculateCost(usage, model);

/**
 * å‘åå…¼å®¹çš„å‡½æ•°ä¿ç•™
 * Normalize usage data from different API response formats
 */
export function normalizeTokenUsage(usage: any): TokenUsage {
  return tokenCounter.normalizeUsage(usage);
}

/**
 * å‘åå…¼å®¹çš„å‡½æ•°ä¿ç•™
 * Get model pricing configuration
 */
export function getModelPricing(model?: string) {
  const normalizedModel = tokenCounter.normalizeModel(model);
  return CLAUDE_PRICING[normalizedModel as keyof typeof CLAUDE_PRICING] || CLAUDE_PRICING.default;
}

/**
 * Calculate detailed token breakdown with cost analysis
 */
export function calculateTokenBreakdown(
  usage: TokenUsage,
  model?: string
): TokenBreakdown {
  return tokenCounter.calculateBreakdown(usage, model);
}

/**
 * Format token count for display with appropriate units
 */
export function formatTokenCount(tokens: number): string {
  return tokenCounter.formatCount(tokens);
}

/**
 * Format cost for display with appropriate precision
 */
export function formatCost(cost: number): string {
  return tokenCounter.formatCost(cost);
}

/**
 * Create a detailed usage summary string
 */
export function formatUsageBreakdown(
  usage: TokenUsage,
  model?: string,
  options: {
    includeTotal?: boolean;
    includeCost?: boolean;
    includeEfficiency?: boolean;
    compact?: boolean;
  } = {}
): string {
  return tokenCounter.formatBreakdown(usage, model, {
    compact: options.compact,
    includeCost: options.includeCost,
    includeEfficiency: options.includeEfficiency
  });
}

/**
 * Create a detailed tooltip with comprehensive token information
 */
export function createTokenTooltip(
  usage: TokenUsage,
  model?: string
): string {
  return tokenCounter.createTooltip(usage, model);
}

/**
 * Aggregate tokens from multiple messages (e.g., for session totals)
 */
export function aggregateTokenUsage(usages: TokenUsage[]): TokenUsage {
  return usages.reduce(
    (total, usage) => {
      const normalized = normalizeTokenUsage(usage);
      return {
        input_tokens: (total.input_tokens || 0) + (normalized.input_tokens || 0),
        output_tokens: (total.output_tokens || 0) + (normalized.output_tokens || 0),
        cache_creation_tokens: (total.cache_creation_tokens || 0) + (normalized.cache_creation_tokens || 0),
        cache_read_tokens: (total.cache_read_tokens || 0) + (normalized.cache_read_tokens || 0),
      };
    },
    { input_tokens: 0, output_tokens: 0, cache_creation_tokens: 0, cache_read_tokens: 0 }
  );
}

/**
 * Calculate session-level statistics with trends
 */
export function calculateSessionStats(
  messages: Array<{ usage?: any; timestamp?: string; receivedAt?: string }>,
  model?: string
): SessionTokenStats {
  // Extract valid usage data from messages
  const usages = messages
    .filter(msg => msg.usage)
    .map(msg => normalizeTokenUsage(msg.usage));

  if (usages.length === 0) {
    return {
      total_tokens: 0,
      total_cost: 0,
      message_count: messages.length,
      average_tokens_per_message: 0,
      cache_efficiency: 0,
      breakdown: calculateTokenBreakdown({ input_tokens: 0, output_tokens: 0 }, model),
      trend: {
        tokens_per_hour: 0,
        cost_per_hour: 0,
      }
    };
  }

  const aggregated = aggregateTokenUsage(usages);
  const breakdown = calculateTokenBreakdown(aggregated, model);

  // Calculate time-based trends
  const timestampedMessages = messages.filter(msg => msg.timestamp || msg.receivedAt);
  let tokensPerHour = 0;
  let costPerHour = 0;
  let peakUsageTime: string | undefined;

  if (timestampedMessages.length >= 2) {
    const firstTime = new Date(timestampedMessages[0].timestamp || timestampedMessages[0].receivedAt!);
    const lastTime = new Date(timestampedMessages[timestampedMessages.length - 1].timestamp || timestampedMessages[timestampedMessages.length - 1].receivedAt!);
    const hoursElapsed = (lastTime.getTime() - firstTime.getTime()) / (1000 * 60 * 60);

    if (hoursElapsed > 0) {
      tokensPerHour = breakdown.total / hoursElapsed;
      costPerHour = breakdown.cost.total_cost / hoursElapsed;
    }
  }

  return {
    total_tokens: breakdown.total,
    total_cost: breakdown.cost.total_cost,
    message_count: messages.length,
    average_tokens_per_message: breakdown.total / messages.length,
    cache_efficiency: breakdown.efficiency.cache_hit_rate,
    breakdown,
    trend: {
      tokens_per_hour: tokensPerHour,
      cost_per_hour: costPerHour,
      peak_usage_time: peakUsageTime,
    }
  };
}

/**
 * Get cached session token data from the API
 */
export async function getSessionCacheTokens(sessionId: string): Promise<{ cache_creation: number; cache_read: number }> {
  try {
    const cacheData = await api.getSessionCacheTokens(sessionId);
    return {
      cache_creation: cacheData.total_cache_creation_tokens,
      cache_read: cacheData.total_cache_read_tokens
    };
  } catch (error) {
    console.warn('Failed to fetch session cache tokens:', error);
    return { cache_creation: 0, cache_read: 0 };
  }
}

export default tokenCounter;
